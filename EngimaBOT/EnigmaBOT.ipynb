{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "445maGBV-GKp"
      },
      "source": [
        "# EnigmaBOT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y21lsIsz-GK3"
      },
      "source": [
        "You've been newly recruited into a secret government agency in a post-apocalyptic world ravaged by a devastating zombie outbreak. Your agency has intercepted an `encrypted transmission` from a rival faction suspected of harboring critical information about the origins of the virus and potential treatments.\n",
        "<br /> <br />\n",
        "However, the encryption used in this transmission is unlike anything your group has encountered before. It appears to be based on an intricate system of linguistic patterns and statistical anomalies, rendering traditional decryption methods useless.\n",
        "<br /> <br />\n",
        "Fortunately, your group has recently acquired a secret technology `EnigmaBOT`, a pre-trained language model that has been exposed to a vast corpus of text spanning medical research, scientific literature, and classified government documents related to viral outbreaks and bioweapons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI8Hax9C-GK8"
      },
      "source": [
        "Your mission is to leverage this pre-trained model's capabilities to decipher the encrypted transmission and uncover any insights or clues that could lead to a cure or a better understanding of the virus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1Hm5s3Y-GK9"
      },
      "source": [
        "- Encrypted transmission: `9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8Kj 2Sq7Ji`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MVypRB3-GK_"
      },
      "source": [
        "## Import necessary libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiMXEAcd-GLB"
      },
      "source": [
        "If you have any missing libraries, you can install them by running the following command in your terminal or command prompt (Make sure you have pip installed): `pip install library1 library2`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyS59bOn-GLD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5Cj8Rvi-GLE"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1O8DJvu-GLF"
      },
      "source": [
        "## RNN model class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2Ws54PD-GLF"
      },
      "source": [
        "The following code should allow you to load the enigmabot model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmT3Aqhk-GLG"
      },
      "outputs": [],
      "source": [
        "class ENIGMABOT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ENIGMABOT, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(256, 32)\n",
        "        self.lstm = nn.LSTM(32,128, 2, batch_first=True, dropout=.1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(128, 256)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.embedding(input)\n",
        "        output = self.lstm(embedded)[0][:,-1,:]\n",
        "        prediction = self.fc(output)\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO9PNQvB-GLH",
        "outputId": "654b70cb-0fc6-4fcb-ed61-e72c6a5fd225"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model = ENIGMABOT()\n",
        "model.load_state_dict(torch.load(\"enigmabot_model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne5J2LzRBECA",
        "outputId": "f4950712-cbc2-4a82-8ccb-9200c963780f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ENIGMABOT(\n",
              "  (embedding): Embedding(256, 32)\n",
              "  (lstm): LSTM(32, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    (2): ELU(alpha=1.0)\n",
              "    (3): Linear(in_features=128, out_features=256, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOA1ATpy-GLH"
      },
      "source": [
        "## Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## some explination :\n",
        "### since we have language model so we should do these steps :\n",
        "\n",
        "\n",
        "1.   convert our string to numbers(all we know ai understand just numbers ðŸ”¢\n",
        "2.   turn them to tensor\n",
        "3.   the output will be the input until we get all the flag\n",
        "\n"
      ],
      "metadata": {
        "id": "2WfxKn9jJi0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"hello\"\n",
        "\n",
        "# Convert input text to ASCII representation\n",
        "ascii_input = [ord(char) for char in input_text]\n",
        "input_tensor = torch.tensor(ascii_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkGVItN1GoN8",
        "outputId": "76ba9f72-59ea-49db-ac48-a949a89beb35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([104, 101, 108, 108, 111])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"9Zx4Qp 8Yw3Po 7Xv2On 6Wu1Nm 5Vt0Ml 4Us9Lk 3Tr8Kj 2Sq7Ji\"\n",
        "ascii_values = [ord(char) for char in input_text]\n",
        "input_tensor = torch.tensor([ascii_values])\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    output = model(input_tensor)\n",
        "\n",
        "\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sciGfdubRd4J",
        "outputId": "a1d82a6d-4bc3-440f-8c08-09b09d832e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMfvrU5XUseL",
        "outputId": "9497cce5-0455-417c-83c0-13d45acce8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.9330, -4.1055, -3.0672, -3.0536, -3.4939, -3.6775, -3.3135, -3.4741,\n",
              "         -3.6486, -3.2803, -3.7822, -3.7483, -3.2000, -3.6906, -3.6204, -3.1931,\n",
              "         -3.4448, -3.3458, -4.2216, -3.1146, -3.0065, -4.6436, -3.0217, -2.5009,\n",
              "         -3.3505, -3.6892, -3.0328, -3.9642, -3.8289, -3.8827, -3.6232, -3.5078,\n",
              "          1.7441, -3.7820, -3.2698, -4.7138, -3.6657, -4.2407, -3.6793, -3.3008,\n",
              "         -3.7128, -2.7638, -3.2557, -4.3565, -4.3096, -3.3595, -0.5079, -3.8348,\n",
              "         -4.1795, -3.0361, -4.0217, -3.2034, -2.5955, -3.6686, -4.7298, -3.1528,\n",
              "         -3.8224, -3.7086, 11.7517, -4.0357, -4.4856, -3.5811, -3.5493, -3.8510,\n",
              "         -3.4796, -1.6326,  1.1275, -3.5197,  0.8826, -6.9957, -3.8773, -3.8053,\n",
              "          0.4453, -0.6176, -3.6198, -2.8796, -4.0380, -1.1918,  1.3303,  0.9725,\n",
              "         -1.1172, -3.4511, -0.8516, -0.0567, -1.9776, -4.7852, -3.3983, -3.7372,\n",
              "         -3.3309, -1.0768, -2.0373, -4.0039, -3.4072, -4.5036, -3.9030, -3.7521,\n",
              "         -3.9462, -2.4730, -4.0345, -3.0039, -3.6274, -3.0502, -3.3172,  0.7795,\n",
              "         -3.7505, -0.9181, -3.8096, -3.5831, -3.5123, -3.4539,  1.2885, -2.2984,\n",
              "         -3.6105, -3.3208, -0.5968, -3.4365, -4.3683, -3.2832, -3.6859, -3.8783,\n",
              "         -4.1794, -4.0137, -4.0473,  1.2541, -4.5298, -2.3095, -3.8405, -4.3597,\n",
              "         -4.2396, -3.8568, -4.0982, -3.9450, -2.8933, -3.4741, -3.8179, -4.3761,\n",
              "         -3.8251, -3.9952, -4.8006, -3.8256, -3.1514, -3.3055, -3.2562, -3.8914,\n",
              "         -3.4064, -4.1179, -3.2869, -3.0420, -2.8610, -3.5562, -4.1110, -3.2936,\n",
              "         -3.0088, -3.0438, -4.1687, -4.1964, -3.3999, -3.3899, -4.3871, -3.6498,\n",
              "         -3.0320, -3.4516, -3.4808, -4.0112, -3.2999, -4.6856, -4.1404, -4.7072,\n",
              "         -3.8322, -2.9036, -4.1875, -3.7614, -3.6746, -4.2260, -4.1652, -3.7928,\n",
              "         -3.9607, -4.1172, -4.1567, -3.5647, -3.8394, -2.9524, -3.7413, -3.1322,\n",
              "         -3.0252, -3.5266, -2.5537, -3.7517, -3.8481, -4.3064, -3.2749, -4.4141,\n",
              "         -3.3451, -3.4299, -3.9745, -3.7467, -3.6062, -3.2245, -4.0433, -4.3183,\n",
              "         -4.2133, -3.1585, -3.7830, -3.2568, -4.2730, -3.0836, -3.7625, -3.8500,\n",
              "         -4.9253, -3.9902, -3.5418, -4.3034, -3.8364, -3.7092, -3.7088, -3.9340,\n",
              "         -3.2798, -2.8184, -3.9792, -4.0340, -3.2611, -3.5806, -3.4486, -4.1927,\n",
              "         -3.7721, -4.9292, -3.8654, -3.2340, -3.2810, -3.5336, -4.1944, -4.1052,\n",
              "         -3.8071, -4.1736, -3.8152, -3.6842, -4.1049, -3.7727, -3.0424, -3.6331,\n",
              "         -2.8655, -2.9893, -3.1646, -3.5094, -3.2543, -4.2618, -4.4973, -3.2477,\n",
              "         -3.9209, -2.6931, -3.1201, -3.2451, -3.2487, -3.7841, -3.6731, -3.8785]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = np.argmax(output, axis=1)"
      ],
      "metadata": {
        "id": "4NpYT2grRQ3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLtwrvItX3mz",
        "outputId": "f2bb82fe-7e7a-4c7a-afb2-2c53a60fdf25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([58])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chr(58)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QsPDltAfRFBD",
        "outputId": "9ab5feef-44e5-46b0-b197-c31ae1f951f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "':'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \": in\"\n",
        "flag = \"\"\n",
        "i = 0\n",
        "for i in range(90) :\n",
        "  ascii_values = [ord(char) for char in input_text]\n",
        "  input_tensor = torch.tensor([ascii_values])\n",
        "\n",
        "\n",
        "  # Pass the input through the model\n",
        "  with torch.no_grad():\n",
        "      model.eval()\n",
        "      output = model(input_tensor)\n",
        "  input_text = input_text + chr(np.argmax(output, axis=1)[0].numpy())"
      ],
      "metadata": {
        "id": "RG5_RgJEb8O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Result ðŸ˜‡"
      ],
      "metadata": {
        "id": "GsYJR9oGKOZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMz7wBr1csr_",
        "outputId": "16b0db8e-eba9-4b7f-9d3e-f37b8d08439c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ": ingeneer{IMMUNEBOOSTERSREADY.PATHOGENMUTATIONSTABILIZED.DISTRIBUTIONPLAN}}}{IMUTABILIZED.DIS\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}